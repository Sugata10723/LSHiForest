{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import sys\n",
    "sys.path.append('/Users/ham/Desktop/research/LSHiForest/src/')\n",
    "from detectors import LSHiForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (7462, 43)\n",
      "X_test shape: (2538, 43)\n",
      "Train normal count: {0: 7462}\n",
      "Test label distribution: {0: 1865, 1: 673}\n"
     ]
    }
   ],
   "source": [
    "features_path = \"NUSW-NB15_features.csv\"\n",
    "data_path = \"UNSW-NB15_1.csv\"\n",
    "\n",
    "# === データ読み込み ===\n",
    "df_features = pd.read_csv(features_path, encoding='cp1252')\n",
    "feature_names = df_features['Name'].tolist()\n",
    "\n",
    "df = pd.read_csv(data_path, header=None, low_memory=False)\n",
    "df.columns = feature_names\n",
    "\n",
    "# データ数制限（最初の10000件を使う）\n",
    "df = df.iloc[:10000, :]\n",
    "\n",
    "# 正常データと異常データを分離\n",
    "normal_data = df[df['Label'] == 0]\n",
    "anomaly_data = df[df['Label'] == 1]\n",
    "\n",
    "# カテゴリカル・数値特徴量の指定\n",
    "categorical_features = [\n",
    "    'sport', 'dsport', 'proto', 'service', 'state', 'is_sm_ips_ports', 'is_ftp_login'\n",
    "]\n",
    "numerical_features = [\n",
    "    \"dur\", \"sbytes\", \"dbytes\", \"sttl\", \"dttl\", \"sloss\", \"dloss\", \"Sload\", \"Dload\", \"Spkts\", \"Dpkts\",\n",
    "    \"swin\", \"dwin\", \"stcpb\", \"dtcpb\", \"smeansz\", \"dmeansz\", \"trans_depth\", \"res_bdy_len\",\n",
    "    \"Sjit\", \"Djit\", \"Sintpkt\", \"Dintpkt\", \"tcprtt\", \"synack\", \"ackdat\", \"ct_state_ttl\",\n",
    "    \"ct_flw_http_mthd\", \"ct_ftp_cmd\", \"ct_srv_src\", \"ct_srv_dst\", \"ct_dst_ltm\",\n",
    "    \"ct_src_ltm\", \"ct_src_dport_ltm\", \"ct_dst_sport_ltm\", \"ct_dst_src_ltm\"\n",
    "]\n",
    "\n",
    "# 正常データを学習・テストに分割\n",
    "train_size = 0.8\n",
    "normal_train = normal_data.sample(frac=train_size, random_state=42)\n",
    "normal_test = normal_data.drop(normal_train.index)\n",
    "\n",
    "# === 数値特徴量のビニング関数 ===\n",
    "def bin_numerical_features(df, numerical_features, n_bins=10):\n",
    "    df_binned = df.copy()\n",
    "    for col in numerical_features:\n",
    "        unique_vals = df[col].nunique()\n",
    "        if unique_vals > n_bins:\n",
    "            df_binned[col] = pd.cut(df[col], bins=n_bins, labels=False)\n",
    "        else:\n",
    "            df_binned[col] = df[col]\n",
    "    return df_binned\n",
    "\n",
    "# トレーニング・テストデータをビニング適用\n",
    "train_binned = bin_numerical_features(normal_train, numerical_features)\n",
    "test_binned = bin_numerical_features(pd.concat([normal_test, anomaly_data]), numerical_features)\n",
    "\n",
    "# 特徴量リスト（カテゴリカル＋ビニング後の数値特徴量）\n",
    "features_to_use = categorical_features + numerical_features\n",
    "\n",
    "# 最終データセット作成\n",
    "X_train = train_binned[features_to_use]\n",
    "y_train = normal_train['Label']  # すべて正常\n",
    "\n",
    "X_test = test_binned[features_to_use]\n",
    "y_test = pd.concat([normal_test, anomaly_data])['Label']\n",
    "\n",
    "# データサイズ出力\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"Train normal count: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Test label distribution: {y_test.value_counts().to_dict()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MinLSH:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ham/Desktop/research/LSHiForest/src/detectors/lsh_tree.py:56: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  children[key] = self._recursive_build(child_data, depth_limit, min(0.0, (children_count[key]-mean)/std), cur_index+1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAUC score:\t 0.22440554676949676\n",
      "\tTraining time:\t 24.048838138580322\n",
      "\tTesting time:\t 72.98170399665833\n"
     ]
    }
   ],
   "source": [
    "num_ensemblers=200\n",
    "classifiers = [(\"MinLSH\", LSHiForest('MinLSH', num_ensemblers))]\n",
    "\n",
    "\n",
    "for i, (clf_name, clf) in enumerate(classifiers):\n",
    "\t\n",
    "\tprint(\"\\n\"+clf_name+\":\")\n",
    "\tstart_time = time.time()\n",
    "\t\n",
    "\tclf.fit(X_train)\n",
    "\t\n",
    "\ttrain_time = time.time()-start_time\n",
    "\t\n",
    "\ty_pred = clf.decision_function(X_test)\n",
    "\t\n",
    "\ttest_time = time.time()-start_time-train_time\n",
    "\t\n",
    "\tauc = roc_auc_score(y_test, y_pred)\n",
    "\t\n",
    "\tprint(\"\\tAUC score:\\t\", auc)\n",
    "\tprint(\"\\tTraining time:\\t\", train_time) \n",
    "\tprint(\"\\tTesting time:\\t\", test_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
